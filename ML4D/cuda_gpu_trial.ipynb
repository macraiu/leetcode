{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(dev)  \n",
    "a = torch.zeros(4,3)    \n",
    "a = a.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "#cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.4092, 0.7210, 0.9469],\n        [0.6282, 0.8794, 0.4301]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.rand(2,3).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-92346228dc1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=576, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7f9033e03190>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "torch.cuda.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    " torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'GeForce GT 750M'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda\n\nGeForce GT 750M\nMemory Usage:\nAllocated: 0.0 GB\nCached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.3244, 0.1577, 0.1757, 0.9855, 0.3596, 0.9142, 0.2831, 0.9329, 0.2312,\n",
       "        0.1245, 0.8279, 0.0640, 0.2826, 0.1068, 0.3222, 0.1630, 0.2270, 0.3112,\n",
       "        0.5748, 0.6186, 0.7165, 0.2802, 0.9195, 0.8298, 0.3469, 0.2882, 0.9643,\n",
       "        0.6968, 0.6768, 0.0928, 0.0061, 0.5333, 0.3340, 0.8205, 0.3186, 0.2719,\n",
       "        0.9698, 0.1869, 0.1003, 0.4833, 0.3368, 0.8283, 0.4289, 0.3356, 0.1624,\n",
       "        0.5723, 0.5441, 0.7492, 0.8340, 0.1056, 0.4510, 0.1722, 0.9147, 0.2724,\n",
       "        0.0416, 0.7608, 0.6549, 0.5119, 0.4370, 0.4103, 0.1489, 0.5404, 0.0551,\n",
       "        0.8925, 0.3806, 0.8141, 0.8987, 0.6562, 0.7613, 0.9101, 0.7337, 0.4132,\n",
       "        0.7478, 0.1351, 0.7293, 0.6007, 0.0318, 0.0210, 0.0768, 0.4725, 0.7737,\n",
       "        0.3090, 0.9714, 0.3350, 0.3148, 0.2548, 0.0826, 0.5997, 0.7538, 0.7937,\n",
       "        0.1403, 0.1279, 0.6730, 0.6933, 0.8432, 0.2497, 0.4889, 0.8617, 0.4056,\n",
       "        0.7780, 0.2732, 0.7698, 0.4049, 0.6898, 0.3120, 0.1949, 0.2766, 0.8021,\n",
       "        0.0133, 0.0615, 0.4563, 0.6103, 0.6408, 0.4296, 0.8768, 0.7703, 0.3678,\n",
       "        0.4159, 0.8827, 0.6164, 0.6687, 0.9430, 0.6592, 0.1691, 0.0758, 0.8877,\n",
       "        0.9620, 0.9630, 0.4994, 0.3808, 0.2969, 0.0232, 0.2321, 0.5399, 0.7842,\n",
       "        0.7614, 0.4303, 0.2843, 0.5874, 0.4652, 0.0757, 0.6847, 0.5653, 0.0177,\n",
       "        0.0044, 0.4589, 0.1155, 0.4152, 0.1685, 0.2358, 0.5547, 0.9861, 0.5387,\n",
       "        0.5605, 0.7906, 0.7306, 0.7939, 0.8345, 0.0122, 0.9175, 0.5875, 0.7078,\n",
       "        0.5103, 0.6232, 0.8811, 0.2057, 0.0047, 0.5646, 0.1391, 0.1275, 0.0936,\n",
       "        0.6630, 0.1095, 0.7777, 0.3346, 0.1079, 0.1639, 0.0847, 0.4108, 0.9073,\n",
       "        0.3080, 0.3959, 0.4452, 0.7678, 0.6300, 0.4906, 0.7460, 0.3867, 0.4213,\n",
       "        0.6663, 0.6729, 0.1135, 0.0074, 0.1154, 0.4355, 0.5433, 0.0453, 0.1304,\n",
       "        0.3129, 0.5445, 0.8229, 0.0086, 0.5913, 0.9557, 0.4256, 0.1216, 0.7627,\n",
       "        0.5642, 0.4015, 0.8402, 0.3652, 0.1177, 0.5131, 0.2632, 0.9989, 0.7773,\n",
       "        0.3655, 0.6029, 0.7788, 0.2775, 0.9525, 0.7123, 0.2133, 0.9764, 0.8399,\n",
       "        0.4118, 0.8180, 0.7646, 0.6331, 0.7092, 0.5718, 0.8555, 0.1880, 0.1255,\n",
       "        0.7918, 0.4008, 0.2380, 0.9455, 0.7814, 0.7338, 0.6882, 0.7492, 0.4400,\n",
       "        0.4139, 0.8120, 0.5899, 0.4906, 0.0962, 0.8706, 0.1524, 0.5933, 0.7358,\n",
       "        0.3810, 0.9872, 0.7958, 0.9375, 0.9607, 0.6889, 0.5224, 0.7590, 0.9337,\n",
       "        0.3530, 0.0959, 0.4478, 0.4696, 0.2480, 0.3688, 0.5182, 0.5112, 0.5294,\n",
       "        0.4937, 0.0557, 0.3410, 0.4079, 0.5485, 0.4634, 0.1366, 0.4427, 0.4234,\n",
       "        0.9787, 0.7983, 0.2225, 0.0542, 0.5228, 0.3068, 0.7852, 0.5432, 0.6436,\n",
       "        0.2375, 0.8481, 0.8091, 0.3547, 0.0005, 0.9791, 0.4990, 0.8529, 0.0561,\n",
       "        0.9614, 0.4751, 0.1450, 0.5883, 0.1432, 0.0466, 0.3954, 0.7590, 0.4659,\n",
       "        0.7976, 0.0991, 0.8812, 0.4093, 0.4054, 0.0918, 0.6551, 0.8517, 0.3085,\n",
       "        0.1316, 0.3678, 0.6757, 0.6458, 0.6907, 0.1066, 0.8220, 0.5208, 0.5678,\n",
       "        0.6250, 0.7981, 0.9335, 0.3189, 0.9094, 0.7318, 0.6233, 0.1859, 0.8523,\n",
       "        0.4108, 0.4654, 0.9474, 0.2678, 0.9409, 0.2044, 0.6037, 0.5407, 0.4102,\n",
       "        0.8008, 0.2486, 0.3328, 0.3724, 0.7422, 0.7207, 0.7590, 0.2484, 0.2682,\n",
       "        0.0677, 0.0838, 0.0913, 0.0658, 0.8273, 0.8563, 0.2493, 0.9393, 0.3635,\n",
       "        0.3847, 0.7058, 0.9308, 0.9974, 0.1375, 0.3259, 0.1534, 0.6849, 0.3629,\n",
       "        0.4803, 0.6070, 0.1714, 0.5149, 0.6493, 0.9143, 0.7867, 0.5192, 0.6105,\n",
       "        0.0061, 0.7663, 0.3923, 0.3034, 0.2165, 0.1919, 0.8269, 0.8049, 0.5209,\n",
       "        0.3841, 0.8235, 0.3772, 0.8470, 0.1178, 0.7684, 0.0036, 0.7015, 0.4819,\n",
       "        0.7481, 0.8674, 0.7048, 0.3941, 0.2485, 0.2448, 0.3879, 0.8623, 0.4602,\n",
       "        0.3740, 0.5215, 0.6516, 0.8296, 0.1514, 0.2066, 0.3882, 0.1185, 0.9734,\n",
       "        0.8923, 0.8097, 0.4454, 0.1434, 0.1214, 0.0964, 0.2520, 0.8894, 0.1412,\n",
       "        0.6126, 0.5842, 0.9715, 0.1239, 0.0719, 0.8127, 0.1756, 0.7582, 0.9997,\n",
       "        0.0216, 0.2278, 0.5144, 0.4495, 0.4989, 0.1732, 0.8090, 0.0712, 0.3267,\n",
       "        0.1526, 0.5990, 0.8333, 0.0646, 0.3373, 0.4237, 0.7828, 0.0160, 0.4448,\n",
       "        0.5043, 0.1885, 0.2523, 0.9168, 0.0429, 0.0142, 0.2379, 0.6707, 0.3165,\n",
       "        0.6966, 0.7010, 0.6216, 0.4866, 0.6152, 0.7374, 0.3648, 0.6408, 0.5745,\n",
       "        0.0841, 0.5128, 0.0519, 0.4026, 0.0198, 0.4684, 0.5740, 0.7121, 0.2028,\n",
       "        0.8784, 0.8078, 0.0712, 0.7089, 0.0528, 0.9801, 0.7541, 0.0761, 0.5772,\n",
       "        0.5068, 0.4745, 0.5274, 0.7357, 0.7025, 0.9502, 0.7840, 0.5771, 0.6273,\n",
       "        0.6680, 0.9559, 0.0086, 0.5243, 0.2181, 0.9178, 0.5369, 0.6623, 0.9951,\n",
       "        0.2819, 0.6026, 0.6971, 0.5419, 0.1096, 0.3377, 0.3303, 0.3269, 0.5646,\n",
       "        0.2479, 0.2233, 0.3887, 0.1768, 0.8102, 0.4622, 0.5486, 0.6548, 0.4097,\n",
       "        0.7666, 0.6810, 0.7164, 0.5738, 0.1965, 0.8107, 0.5498, 0.4778, 0.0132,\n",
       "        0.2416, 0.5028, 0.0100, 0.4989, 0.3893, 0.1592, 0.6847, 0.3472, 0.9025,\n",
       "        0.8092, 0.7670, 0.7634, 0.3656, 0.1664, 0.1920, 0.5052, 0.1506, 0.0122,\n",
       "        0.9839, 0.2561, 0.1586, 0.8680, 0.3994, 0.6443, 0.4988, 0.1674, 0.3894,\n",
       "        0.3361, 0.5227, 0.1648, 0.5738, 0.4767, 0.8760, 0.8775, 0.5520, 0.5757,\n",
       "        0.7966, 0.4565, 0.2106, 0.4683, 0.5662, 0.8805, 0.6797, 0.2170, 0.3421,\n",
       "        0.4092, 0.0554, 0.2665, 0.8638, 0.6785, 0.8466, 0.3433, 0.2970, 0.3863,\n",
       "        0.5308, 0.9171, 0.8244, 0.5531, 0.0706, 0.5836, 0.4313, 0.1388, 0.0244,\n",
       "        0.9941, 0.9351, 0.9101, 0.0428, 0.4819, 0.3052, 0.5598, 0.3855, 0.4664,\n",
       "        0.1579, 0.6730, 0.1897, 0.3114, 0.1698, 0.0411, 0.8584, 0.3957, 0.6377,\n",
       "        0.4081, 0.8718, 0.1309, 0.9216, 0.9822, 0.8069, 0.8199, 0.0063, 0.2001,\n",
       "        0.8056, 0.6076, 0.6491, 0.1452, 0.9717, 0.3750, 0.7137, 0.6756, 0.0435,\n",
       "        0.5168, 0.0517, 0.4626, 0.0177, 0.7303, 0.6682, 0.7712, 0.9357, 0.4886,\n",
       "        0.0985, 0.7059, 0.8382, 0.2564, 0.2365, 0.7808, 0.9464, 0.5234, 0.5797,\n",
       "        0.8536, 0.1128, 0.5419, 0.5265, 0.0435, 0.7441, 0.8797, 0.7358, 0.3666,\n",
       "        0.9339, 0.3677, 0.5807, 0.5369, 0.1789, 0.2401, 0.8035, 0.9775, 0.9021,\n",
       "        0.2968, 0.3872, 0.2880, 0.0766, 0.2689, 0.4024, 0.8324, 0.7701, 0.4767,\n",
       "        0.5877, 0.8815, 0.4615, 0.2781, 0.3718, 0.4129, 0.4292, 0.5839, 0.5158,\n",
       "        0.1231, 0.5159, 0.6953, 0.3631, 0.7924, 0.5981, 0.3829, 0.5003, 0.5201,\n",
       "        0.0897, 0.1760, 0.5362, 0.4909, 0.7851, 0.3293, 0.9168, 0.1667, 0.6772,\n",
       "        0.9516, 0.5601, 0.1366, 0.6027, 0.4046, 0.2913, 0.5230, 0.8173, 0.9890,\n",
       "        0.0647, 0.3182, 0.1290, 0.9848, 0.1292, 0.7648, 0.7792, 0.7248, 0.8232,\n",
       "        0.4419, 0.6026, 0.9656, 0.5620, 0.7606, 0.7362, 0.4807, 0.6456, 0.9861,\n",
       "        0.8110, 0.0587, 0.8378, 0.3721, 0.8154, 0.9428, 0.9490, 0.2903, 0.9733,\n",
       "        0.7923, 0.8574, 0.4033, 0.5230, 0.5837, 0.9211, 0.1211, 0.9411, 0.8338,\n",
       "        0.7316, 0.7013, 0.0354, 0.7427, 0.5955, 0.2344, 0.5706, 0.0762, 0.1947,\n",
       "        0.6934, 0.9518, 0.5211, 0.4498, 0.9926, 0.0350, 0.5052, 0.9948, 0.4689,\n",
       "        0.1959, 0.5273, 0.0911, 0.8633, 0.6811, 0.1496, 0.6563, 0.5050, 0.6430,\n",
       "        0.3367, 0.7133, 0.8848, 0.8941, 0.7445, 0.0575, 0.1012, 0.6450, 0.3467,\n",
       "        0.6761, 0.0494, 0.8210, 0.3233, 0.9555, 0.0796, 0.8493, 0.9168, 0.2360,\n",
       "        0.3143, 0.3825, 0.1406, 0.4589, 0.8266, 0.2066, 0.5237, 0.8536, 0.9795,\n",
       "        0.1400, 0.1965, 0.8861, 0.0002, 0.3407, 0.6272, 0.9367, 0.8767, 0.4761,\n",
       "        0.4288, 0.4806, 0.0602, 0.0234, 0.2433, 0.4679, 0.9370, 0.0366, 0.7820,\n",
       "        0.7034, 0.1955, 0.9645, 0.8063, 0.7762, 0.1516, 0.5032, 0.1263, 0.6489,\n",
       "        0.0856, 0.0818, 0.7177, 0.9968, 0.7446, 0.6620, 0.0716, 0.5750, 0.2220,\n",
       "        0.7804, 0.3901, 0.1320, 0.4863, 0.3395, 0.2748, 0.8253, 0.0565, 0.0863,\n",
       "        0.5951, 0.8651, 0.1081, 0.3688, 0.7973, 0.5635, 0.5072, 0.4177, 0.7453,\n",
       "        0.9237, 0.8193, 0.3177, 0.2488, 0.9898, 0.8605, 0.2912, 0.4783, 0.8140,\n",
       "        0.7960, 0.5679, 0.8421, 0.2954, 0.7571, 0.3704, 0.5414, 0.0792, 0.3002,\n",
       "        0.4716, 0.1736, 0.2545, 0.4251, 0.1349, 0.8633, 0.2281, 0.5171, 0.0663,\n",
       "        0.8635, 0.4271, 0.5550, 0.0266, 0.5113, 0.5173, 0.1146, 0.2324, 0.3894,\n",
       "        0.0250, 0.3666, 0.3902, 0.1106, 0.5227, 0.7280, 0.1310, 0.7602, 0.0237,\n",
       "        0.0051, 0.9567, 0.2542, 0.2266, 0.8118, 0.5693, 0.9727, 0.6597, 0.1593,\n",
       "        0.4468, 0.2039, 0.9611, 0.1996, 0.6528, 0.3083, 0.2425, 0.2346, 0.0870,\n",
       "        0.6211, 0.8526, 0.8022, 0.1929, 0.7739, 0.3299, 0.5029, 0.0280, 0.7815,\n",
       "        0.6031, 0.1684, 0.1488, 0.2531, 0.0289, 0.2017, 0.6135, 0.8921, 0.5873,\n",
       "        0.5210, 0.3794, 0.1711, 0.1686, 0.5774, 0.0120, 0.1544, 0.8498, 0.8034,\n",
       "        0.2535, 0.5078, 0.6425, 0.9378, 0.8458, 0.5262, 0.9586, 0.0363, 0.8961,\n",
       "        0.0178, 0.6517, 0.2328, 0.2740, 0.0040, 0.8209, 0.7839, 0.6552, 0.3423,\n",
       "        0.0613, 0.3148, 0.4572, 0.7838, 0.7505, 0.4125, 0.6337, 0.2003, 0.9700,\n",
       "        0.0921, 0.6239, 0.8796, 0.9596, 0.8588, 0.2018, 0.2961, 0.0563, 0.6721,\n",
       "        0.1897, 0.8840, 0.6375, 0.9256, 0.3222, 0.7736, 0.9600, 0.6058, 0.6734,\n",
       "        0.5289, 0.2862, 0.0126, 0.5742, 0.7630, 0.7236, 0.9431, 0.9491, 0.9093,\n",
       "        0.6734], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "torch.rand(1000).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Beginning Randomly Generated Weights: \n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "Ending Weights After Training: \n",
      "[[10.08740896]\n",
      " [-0.20695366]\n",
      " [-4.83757835]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # seeding for random number generation\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        #converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
    "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        #applying the sigmoid function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        #computing derivative to the Sigmoid function\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train(self, training_inputs, training_outputs, training_iterations):\n",
    "        \n",
    "        #training the model to make accurate predictions while adjusting weights continually\n",
    "        for iteration in range(training_iterations):\n",
    "            #siphon the training data via  the neuron\n",
    "            output = self.think(training_inputs)\n",
    "\n",
    "            #computing error rate for back-propagation\n",
    "            error = training_outputs - output\n",
    "            \n",
    "            #performing weight adjustments\n",
    "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
    "\n",
    "            self.synaptic_weights += adjustments\n",
    "\n",
    "    def think(self, inputs):\n",
    "        #passing the inputs via the neuron to get output   \n",
    "        #converting values to floats\n",
    "        \n",
    "        inputs = inputs.astype(float)\n",
    "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
    "        return output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #initializing the neuron class\n",
    "    neural_network = NeuralNetwork()\n",
    "\n",
    "    print(\"Beginning Randomly Generated Weights: \")\n",
    "    print(neural_network.synaptic_weights)\n",
    "\n",
    "    #training data consisting of 4 examples--3 input values and 1 output\n",
    "    training_inputs = np.array([[0,0,1],\n",
    "                                [1,1,1],\n",
    "                                [1,0,1],\n",
    "                                [0,1,1]])\n",
    "\n",
    "    training_outputs = np.array([[0,1,1,0]]).T\n",
    "\n",
    "    #training taking place\n",
    "    neural_network.train(training_inputs, training_outputs, 15000)\n",
    "\n",
    "    print(\"Ending Weights After Training: \")\n",
    "    print(neural_network.synaptic_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "elapsed time 0.6828737258911133\nResult: y = -0.2790149450302124 + -1.331552267074585 x + 1.7954853773117065 x^2 + -1.4032344818115234 x^3\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "\n",
    "start_time = time.time()\n",
    "# your code\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "\n",
    "for t in range(20000):\n",
    "\n",
    "    # Randomly initialize weights\n",
    "    a = torch.randn((), device=device, dtype=dtype)\n",
    "    b = torch.randn((), device=device, dtype=dtype)\n",
    "    c = torch.randn((), device=device, dtype=dtype)\n",
    "    d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"elapsed time\", elapsed_time)\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, random, os\n",
    "lr = 1 #learning rate\n",
    "bias = 1 #value of bias\n",
    "weights = [random.random(),random.random(),random.random()] #weights generated in a list (3 weights in total for 2 neurons and the bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perceptron(input1, input2, output) :\n",
    "   outputP = input1*weights[0]+input2*weights[1]+bias*weights[2]\n",
    "   if outputP > 0 : #activation function (here Heaviside)\n",
    "      outputP = 1\n",
    "   else :\n",
    "      outputP = 0\n",
    "   error = output - outputP\n",
    "   weights[0] += error * input1 * lr\n",
    "   weights[1] += error * input2 * lr\n",
    "   weights[2] += error * bias * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50) :\n",
    "   Perceptron(1,1,1) #True or true\n",
    "   Perceptron(1,0,1) #True or false\n",
    "   Perceptron(0,1,1) #False or true\n",
    "   Perceptron(0,0,0) #False or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-800a17e59093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutputP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutputP\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m#activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0moutputP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "x = int(input())\n",
    "y = int(input())\n",
    "outputP = x*weights[0] + y*weights[1] + bias*weights[2]\n",
    "if outputP > 0 : #activation function\n",
    "   outputP = 1\n",
    "else :\n",
    "   outputP = 0\n",
    "print(x, \"or\", y, \"is : \", outputP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputP = 1/(1+numpy.exp(-outputP)) #sigmoid function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6750375273768237\n"
     ]
    }
   ],
   "source": [
    "print(outputP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}